{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a25b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import utils_datasets as utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8c83b",
   "metadata": {},
   "source": [
    "# Construction of the datasets\n",
    "\n",
    "We'll first construct our datasets on several stocks listed in tickers. For each ticker and from a period going from START_TIME to today we will construct the following dataset. For a rolling window of N_DAYS over the subsequent period we'll construct an image containing\n",
    "- 20 days mooving avergae.\n",
    "- volume traded for each days\n",
    "- opening and and closing prices.\n",
    "- highest and lowest prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac9e0c",
   "metadata": {},
   "source": [
    "## Construction of second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "importlib.reload(utils)\n",
    "tickers = [\n",
    "    \"GE\",    # General Electric – Conglomerate\n",
    "    \"CAT\",   # Caterpillar – Construction machinery & equipment\n",
    "    \"DE\",    # Deere & Co. – Agricultural & heavy equipment\n",
    "    \"HON\",   # Honeywell – Industrial automation & aerospace\n",
    "    \"MMM\",   # 3M – Industrial products & diversified tech\n",
    "    \"BA\",    # Boeing – Aerospace & defense\n",
    "    \"LMT\",   # Lockheed Martin – Defense contractor\n",
    "    \"RTX\",   # Raytheon Technologies – Aerospace & defense\n",
    "    \"NOC\",   # Northrop Grumman – Military tech & aerospace\n",
    "    \"EMR\",   # Emerson Electric – Industrial automation\n",
    "    \"ETN\",   # Eaton – Power management & electrical systems\n",
    "    \"ITW\",   # Illinois Tool Works – Industrial manufacturing\n",
    "    \"PH\",    # Parker-Hannifin – Motion & control technologies\n",
    "    \"UPS\",   # UPS – Global logistics & transportation\n",
    "    \"FDX\"    # FedEx – Courier & freight logistics\n",
    "]\n",
    "for ticker in tickers:\n",
    "    result = utils.create_data_set_bis(ticker, tresh = 0.007, target_size=None, ma = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b293596",
   "metadata": {},
   "source": [
    "# Manipulation and visualisation of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9dfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "tickers = [\n",
    "    \"GE\",    # General Electric – Conglomerate\n",
    "    \"CAT\",   # Caterpillar – Construction machinery & equipment\n",
    "    \"DE\",    # Deere & Co. – Agricultural & heavy equipment\n",
    "    \"HON\",   # Honeywell – Industrial automation & aerospace\n",
    "    \"MMM\",   # 3M – Industrial products & diversified tech\n",
    "    \"BA\",    # Boeing – Aerospace & defense\n",
    "    \"LMT\",   # Lockheed Martin – Defense contractor\n",
    "    \"RTX\",   # Raytheon Technologies – Aerospace & defense\n",
    "    \"NOC\",   # Northrop Grumman – Military tech & aerospace\n",
    "    \"EMR\",   # Emerson Electric – Industrial automation\n",
    "    \"ETN\",   # Eaton – Power management & electrical systems\n",
    "    \"ITW\",   # Illinois Tool Works – Industrial manufacturing\n",
    "    \"PH\",    # Parker-Hannifin – Motion & control technologies\n",
    "    \"UPS\",   # UPS – Global logistics & transportation\n",
    "    \"FDX\"    # FedEx – Courier & freight logistics\n",
    "]\n",
    "res = pd.DataFrame()\n",
    "for tick in tickers:\n",
    "    TICKER_DATA_DATE = yf.download(tick, start=\"2000-01-01\", auto_adjust=True, interval='1d')\n",
    "    TICKER_DATA_DATE.columns = TICKER_DATA_DATE.columns.get_level_values(0)\n",
    "    TICKER_DATA_DATE = TICKER_DATA_DATE[['Open', 'Close', 'High', 'Low', 'Volume']].copy()\n",
    "    #TICKER_DATA_DATE['Return'] = TICKER_DATA_DATE['Close'].pct_change()\n",
    "    TICKER_DATA_DATE['Name'] = [tick] * len(TICKER_DATA_DATE)\n",
    "    TICKER_DATA_DATE.columns.name = None \n",
    "    res = pd.concat([res, TICKER_DATA_DATE], axis = 0, ignore_index=True)\n",
    "res.dropna(inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "res['Return'] = np.log(res['Close'] / res['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "# Clean data\n",
    "res = res.dropna(subset=['Return']).copy()\n",
    "res['Return'] = res['Return'].clip(lower=-0.1, upper=0.1)\n",
    "\n",
    "tickers = res['Name'].unique()\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(15, 8))\n",
    "common_sample_size = 1000\n",
    "\n",
    "# Plot individual KDEs\n",
    "for ticker in tickers:\n",
    "    sub = res[res['Name'] == ticker]['Return'].sample(n=common_sample_size, random_state=42)\n",
    "    sns.kdeplot(\n",
    "        sub,\n",
    "        label=ticker,\n",
    "        fill=False,\n",
    "        linewidth=1,\n",
    "        bw_adjust=1.2\n",
    "    )\n",
    "\n",
    "# Plot overall KDE\n",
    "sampled = res['Return'].sample(n=common_sample_size, random_state=42)\n",
    "sns.kdeplot(\n",
    "    sampled,\n",
    "    color='white',\n",
    "    linewidth=4,\n",
    "    fill=True,\n",
    "    alpha=0.4,\n",
    "    label='Overall',\n",
    "    bw_adjust=1.2\n",
    ")\n",
    "\n",
    "# Axis settings\n",
    "plt.xlim(-0.05, 0.05)\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Vertical line at 0.7%\n",
    "plt.axvline(0.007, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Threshold 0.7%')\n",
    "\n",
    "# Final polish\n",
    "plt.title(\"Distribution of Daily Returns by Ticker\", fontsize=18, weight='bold')\n",
    "plt.xlabel(\"Daily Return\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "plt.axvline(0, color='white', linestyle='--', alpha=0.3)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(\n",
    "    title='Ticker',\n",
    "    fontsize=12,\n",
    "    title_fontsize=14,\n",
    "    ncol=3,\n",
    "    loc='upper right',\n",
    "    frameon=True\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ed024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Log of close prices\n",
    "res = res[res['Name'] == 'UPS']\n",
    "log_prices = np.log(res['Close'].dropna())\n",
    "\n",
    "# Histogram and KDE\n",
    "sns.histplot(log_prices, kde=True)\n",
    "plt.title(\"Log of Close Prices\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(log_prices, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Log Prices\")\n",
    "plt.show()\n",
    "\n",
    "# Normality test\n",
    "stat, p = stats.shapiro(log_prices)\n",
    "print(\"Shapiro-Wilk p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da550a",
   "metadata": {},
   "source": [
    "## Drop the indexes that will be used to compute the hedging (this indexes have been determined later, see the result notebook), \n",
    "- Explanation: It's better to keep two versions of the dataset, one for training that doesn't contain the file droped below and another one used in the result notebook that will be used to determine on whihc stock and which time window our hedging will be realized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "begin = 2206 \n",
    "end = 2245\n",
    "path_images =  os.path.join(os.getcwd(), 'v-b', 'UPS', 'images')\n",
    "path_labels = os.path.join(os.getcwd(), 'v-b', 'UPS', 'labels', 'labels.csv')\n",
    "old_labels = pd.read_csv(path_labels)\n",
    "new_labels = old_labels[((old_labels['id'] < begin) | (old_labels['id'] >= end))]\n",
    "new_labels.to_csv(path_labels)\n",
    "\n",
    "for i in range(begin, end):\n",
    "    filename = f\"{i}.png\"                     # adapt extension\n",
    "    img_path = os.path.join(path_images, filename)\n",
    "\n",
    "    if os.path.isfile(img_path):\n",
    "        os.remove(img_path)\n",
    "        deleted += 1\n",
    "    else:\n",
    "        missing += 1\n",
    "\n",
    "print(f\"Removed {deleted} images; {missing} not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "these_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
